{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×10 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮                      \n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "using TensorFlow\n",
    "using Distributions\n",
    "using Printf\n",
    "\n",
    "# Generate some synthetic data\n",
    "x = randn(100, 50)\n",
    "w = randn(50, 10)\n",
    "y_prob = exp.(x*w)\n",
    "y_prob ./= sum(y_prob,dims=2)\n",
    "\n",
    "function draw(probs)\n",
    "   y = zeros(size(probs))\n",
    "   for i in 1:size(probs, 1)\n",
    "       idx = rand(Categorical(probs[i, :]))\n",
    "       y[i, idx] = 1\n",
    "   end\n",
    "   return y\n",
    "end\n",
    "\n",
    "y = draw(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-20 20:16:42.935650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:16:42.937154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569\n",
      "pciBusID: 0000:02:00.0\n",
      "2019-08-20 20:16:42.937270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-08-20 20:16:42.937325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2019-08-20 20:16:42.937371: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2019-08-20 20:16:42.937419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2019-08-20 20:16:42.937463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-08-20 20:16:42.937504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-08-20 20:16:42.937543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-08-20 20:16:42.937771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:16:42.939178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:16:42.940482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-08-20 20:16:42.940605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-20 20:16:42.940640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-08-20 20:16:42.940666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-08-20 20:16:42.940965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:16:42.942344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:16:42.943646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5637 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Tensor Softmax:1 shape=(?, 10) dtype=Float64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "sess = Session(Graph())\n",
    "\n",
    "X = placeholder(Float64, shape=[-1, 50])\n",
    "Y_obs = placeholder(Float64, shape=[-1, 10])\n",
    "\n",
    "variable_scope(\"logisitic_model\"; initializer=Normal(0, .001)) do\n",
    "   global W = get_variable(\"W\", [50, 10], Float64)\n",
    "   global B = get_variable(\"B\", [10], Float64)\n",
    "end\n",
    "\n",
    "Y=nn.softmax(X*W + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamOptimizer(η=0.001, β1=0.9, β2=0.999, ϵ=1.0e-8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Loss = -reduce_sum(log(Y).*Y_obs)\n",
    " optimizer = train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Your Python TensorFlow client version (1.13.1) is below the TensorFlow backend version (1.14.0). This can cause various errors. Please upgrade your Python TensorFlow installation and then restart Julia.\n",
      "│ You can upgrade by calling `using Conda; Conda.update();` from Julia.\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/version.jl:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "      From worker 10:\t/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "      From worker 10:\t  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "      From worker 10:\tWARNING:tensorflow:From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:80: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "      From worker 10:\tInstructions for updating:\n",
      "      From worker 10:\tColocations handled automatically by placer.\n",
      "      From worker 10:\tWARNING:tensorflow:From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "      From worker 10:\tInstructions for updating:\n",
      "      From worker 10:\tUse tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Saver>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize_op = train.minimize(optimizer, Loss)\n",
    "saver = train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Checkpoint files saved in /tmp/tmpjATbBF\n",
      "└ @ Main In[10]:4\n",
      "2019-08-20 20:17:45.027450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 230.23.\n",
      "Current loss is 228.76.\n",
      "Current loss is 227.29.\n",
      "Current loss is 225.84.\n",
      "Current loss is 224.39.\n",
      "Current loss is 222.95.\n",
      "Current loss is 221.52.\n",
      "Current loss is 220.09.\n",
      "Current loss is 218.67.\n",
      "Current loss is 217.26.\n",
      "Current loss is 215.86.\n",
      "Current loss is 214.46.\n",
      "Current loss is 213.08.\n",
      "Current loss is 211.70.\n",
      "Current loss is 210.33.\n",
      "Current loss is 208.96.\n",
      "Current loss is 207.61.\n",
      "Current loss is 206.26.\n",
      "Current loss is 204.92.\n",
      "Current loss is 203.59.\n",
      "Current loss is 202.27.\n",
      "Current loss is 200.96.\n",
      "Current loss is 199.65.\n",
      "Current loss is 198.36.\n",
      "Current loss is 197.07.\n",
      "Current loss is 195.79.\n",
      "Current loss is 194.52.\n",
      "Current loss is 193.26.\n",
      "Current loss is 192.00.\n",
      "Current loss is 190.76.\n",
      "Current loss is 189.52.\n",
      "Current loss is 188.29.\n",
      "Current loss is 187.07.\n",
      "Current loss is 185.86.\n",
      "Current loss is 184.66.\n",
      "Current loss is 183.46.\n",
      "Current loss is 182.27.\n",
      "Current loss is 181.10.\n",
      "Current loss is 179.93.\n",
      "Current loss is 178.77.\n",
      "Current loss is 177.61.\n",
      "Current loss is 176.47.\n",
      "Current loss is 175.33.\n",
      "Current loss is 174.20.\n",
      "Current loss is 173.08.\n",
      "Current loss is 171.97.\n",
      "Current loss is 170.87.\n",
      "Current loss is 169.77.\n",
      "Current loss is 168.68.\n",
      "Current loss is 167.61.\n",
      "Current loss is 166.53.\n",
      "Current loss is 165.47.\n",
      "Current loss is 164.41.\n",
      "Current loss is 163.37.\n",
      "Current loss is 162.33.\n",
      "Current loss is 161.29.\n",
      "Current loss is 160.27.\n",
      "Current loss is 159.25.\n",
      "Current loss is 158.24.\n",
      "Current loss is 157.24.\n",
      "Current loss is 156.24.\n",
      "Current loss is 155.26.\n",
      "Current loss is 154.28.\n",
      "Current loss is 153.30.\n",
      "Current loss is 152.34.\n",
      "Current loss is 151.38.\n",
      "Current loss is 150.43.\n",
      "Current loss is 149.49.\n",
      "Current loss is 148.55.\n",
      "Current loss is 147.62.\n",
      "Current loss is 146.70.\n",
      "Current loss is 145.78.\n",
      "Current loss is 144.87.\n",
      "Current loss is 143.97.\n",
      "Current loss is 143.08.\n",
      "Current loss is 142.19.\n",
      "Current loss is 141.31.\n",
      "Current loss is 140.43.\n",
      "Current loss is 139.56.\n",
      "Current loss is 138.70.\n",
      "Current loss is 137.85.\n",
      "Current loss is 137.00.\n",
      "Current loss is 136.16.\n",
      "Current loss is 135.32.\n",
      "Current loss is 134.49.\n",
      "Current loss is 133.67.\n",
      "Current loss is 132.85.\n",
      "Current loss is 132.04.\n",
      "Current loss is 131.24.\n",
      "Current loss is 130.44.\n",
      "Current loss is 129.64.\n",
      "Current loss is 128.86.\n",
      "Current loss is 128.08.\n",
      "Current loss is 127.30.\n",
      "Current loss is 126.53.\n",
      "Current loss is 125.77.\n",
      "Current loss is 125.01.\n",
      "Current loss is 124.26.\n",
      "Current loss is 123.51.\n",
      "Current loss is 122.77.\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    " run(sess, global_variables_initializer())\n",
    " checkpoint_path = mktempdir()\n",
    " @info(\"Checkpoint files saved in $checkpoint_path\")\n",
    " for epoch in 1:100\n",
    "    cur_loss, _ = run(sess, [Loss, minimize_op], Dict(X=>x, Y_obs=>y))\n",
    "    println(@sprintf(\"Current loss is %.2f.\", cur_loss))\n",
    "    train.save(saver, sess, joinpath(checkpoint_path, \"logistic\"), global_step=epoch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Status\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      " \u001b[90m [28f6a940]\u001b[39m\u001b[37m TensorFlow v0.12.0 #master (https://github.com/malmaud/TensorFlow.jl.git)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.status(\"TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dreuter/.julia/conda/3/lib/libpython3.7m.so.1.0\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyCall.libpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dreuter/.julia/conda/3/bin/python\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyCall.pyprogramname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/dreuter/.julia/conda/3:/home/dreuter/.julia/conda/3\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyCall.PYTHONHOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-20 20:18:27.304800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:18:27.305375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569\n",
      "pciBusID: 0000:02:00.0\n",
      "2019-08-20 20:18:27.305405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-08-20 20:18:27.305416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2019-08-20 20:18:27.305425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2019-08-20 20:18:27.305433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2019-08-20 20:18:27.305441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-08-20 20:18:27.305449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-08-20 20:18:27.305457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-08-20 20:18:27.305500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:18:27.306082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:18:27.306650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-08-20 20:18:27.306690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-20 20:18:27.306697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-08-20 20:18:27.306703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-08-20 20:18:27.306788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:18:27.307361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:18:27.307949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5637 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "using TensorFlow\n",
    "include(\"mnist_loader.jl\")\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "sess = Session(Graph())\n",
    "\n",
    "x = placeholder(Float32)\n",
    "y_ = placeholder(Float32)\n",
    "\n",
    "W = Variable(zeros(Float32, 784, 10))\n",
    "b = Variable(zeros(Float32, 10))\n",
    "\n",
    "run(sess, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce_2:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y = nn.softmax(x*W + b)\n",
    " cross_entropy = reduce_mean(-reduce_sum(y_ .* log(y), axis=[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Group_3:1 shape=() dtype=Any>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_step = train.minimize(train.GradientDescentOptimizer(.0001,\"gd\"), cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n:o 1\n",
      "Batch n:o 2\n",
      "Batch n:o 3\n",
      "Batch n:o 4\n",
      "Batch n:o 5\n",
      "Batch n:o 6\n",
      "Batch n:o 7\n",
      "Batch n:o 8\n",
      "Batch n:o 9\n",
      "Batch n:o 10\n",
      "Batch n:o 11\n",
      "Batch n:o 12\n",
      "Batch n:o 13\n",
      "Batch n:o 14\n",
      "Batch n:o 15\n",
      "Batch n:o 16\n",
      "Batch n:o 17\n",
      "Batch n:o 18\n",
      "Batch n:o 19\n",
      "Batch n:o 20\n",
      "Batch n:o 21\n",
      "Batch n:o 22\n",
      "Batch n:o 23\n",
      "Batch n:o 24\n",
      "Batch n:o 25\n",
      "Batch n:o 26\n",
      "Batch n:o 27\n",
      "Batch n:o 28\n",
      "Batch n:o 29\n",
      "Batch n:o 30\n",
      "Batch n:o 31\n",
      "Batch n:o 32\n",
      "Batch n:o 33\n",
      "Batch n:o 34\n",
      "Batch n:o 35\n",
      "Batch n:o 36\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] _string_n at ./strings/string.jl:60 [inlined]",
      " [2] string(::String, ::String) at ./strings/substring.jl:180",
      " [3] *(::String, ::String) at ./strings/basic.jl:229",
      " [4] close(::GZip.GZipStream) at /home/dreuter/.julia/packages/GZip/LD2ly/src/GZip.jl:312",
      " [5] gzopen(::getfield(MLDatasets.MNIST.Reader, Symbol(\"##1#2\")){Int64}, ::String, ::String) at /home/dreuter/.julia/packages/GZip/LD2ly/src/GZip.jl:270",
      " [6] readimages at /home/dreuter/.julia/packages/MLDatasets/yNB45/src/MNIST/Reader/readimages.jl:68 [inlined]",
      " [7] #traintensor#2 at /home/dreuter/.julia/packages/MLDatasets/yNB45/src/MNIST/interface.jl:55 [inlined]",
      " [8] #traintensor at ./none:0 [inlined]",
      " [9] #traindata#10 at /home/dreuter/.julia/packages/MLDatasets/yNB45/src/MNIST/interface.jl:231 [inlined]",
      " [10] #traindata at ./none:0 [inlined]",
      " [11] #traindata#11 at /home/dreuter/.julia/packages/MLDatasets/yNB45/src/MNIST/interface.jl:235 [inlined]",
      " [12] traindata at /home/dreuter/.julia/packages/MLDatasets/yNB45/src/MNIST/interface.jl:235 [inlined]",
      " [13] next_batch at /home/dreuter/Github/julia-paths/LearningPath-Julia/mnist_loader.jl:15 [inlined]",
      " [14] top-level scope at ./In[17]:5"
     ]
    }
   ],
   "source": [
    "correct_prediction = argmax(y, 2) .== argmax(y_, 2)\n",
    "accuracy=reduce_mean(cast(correct_prediction, Float32))\n",
    "\n",
    "for i in 1:1000\n",
    "    batch = next_batch(loader, 100)\n",
    "    println(\"Batch n:o $(i)\")\n",
    "    run(sess, train_step, Dict(x=>batch[1], y_=>batch[2]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx, testy = load_test_set()\n",
    "println(run(sess, accuracy, Dict(x=>testx, y_=>testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.1/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DataStructures\")\n",
    "Pkg.build(\"DataStructures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-20 20:35:17.593449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:35:17.593736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569\n",
      "pciBusID: 0000:02:00.0\n",
      "2019-08-20 20:35:17.593759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-08-20 20:35:17.593767: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2019-08-20 20:35:17.593773: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2019-08-20 20:35:17.593779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2019-08-20 20:35:17.593785: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-08-20 20:35:17.593790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-08-20 20:35:17.593796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-08-20 20:35:17.593833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:35:17.594057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:35:17.594245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-08-20 20:35:17.594268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-20 20:35:17.594272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-08-20 20:35:17.594276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-08-20 20:35:17.594327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:35:17.594539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:35:17.594764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5637 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "┌ Info: Checkpoint files saved in /tmp/tmpsjn1vc\n",
      "└ @ Main In[3]:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 230.21.\n",
      "Current loss is 228.76.\n",
      "Current loss is 227.30.\n",
      "Current loss is 225.86.\n",
      "Current loss is 224.43.\n",
      "Current loss is 223.00.\n",
      "Current loss is 221.58.\n",
      "Current loss is 220.16.\n",
      "Current loss is 218.75.\n",
      "Current loss is 217.36.\n",
      "Current loss is 215.97.\n",
      "Current loss is 214.58.\n",
      "Current loss is 213.21.\n",
      "Current loss is 211.84.\n",
      "Current loss is 210.48.\n",
      "Current loss is 209.14.\n",
      "Current loss is 207.79.\n",
      "Current loss is 206.46.\n",
      "Current loss is 205.14.\n",
      "Current loss is 203.82.\n",
      "Current loss is 202.52.\n",
      "Current loss is 201.22.\n",
      "Current loss is 199.93.\n",
      "Current loss is 198.65.\n",
      "Current loss is 197.38.\n",
      "Current loss is 196.11.\n",
      "Current loss is 194.86.\n",
      "Current loss is 193.61.\n",
      "Current loss is 192.38.\n",
      "Current loss is 191.15.\n",
      "Current loss is 189.93.\n",
      "Current loss is 188.72.\n",
      "Current loss is 187.52.\n",
      "Current loss is 186.33.\n",
      "Current loss is 185.15.\n",
      "Current loss is 183.97.\n",
      "Current loss is 182.81.\n",
      "Current loss is 181.65.\n",
      "Current loss is 180.50.\n",
      "Current loss is 179.36.\n",
      "Current loss is 178.23.\n",
      "Current loss is 177.11.\n",
      "Current loss is 176.00.\n",
      "Current loss is 174.89.\n",
      "Current loss is 173.80.\n",
      "Current loss is 172.71.\n",
      "Current loss is 171.63.\n",
      "Current loss is 170.56.\n",
      "Current loss is 169.49.\n",
      "Current loss is 168.44.\n",
      "Current loss is 167.39.\n",
      "Current loss is 166.35.\n",
      "Current loss is 165.32.\n",
      "Current loss is 164.30.\n",
      "Current loss is 163.29.\n",
      "Current loss is 162.28.\n",
      "Current loss is 161.28.\n",
      "Current loss is 160.29.\n",
      "Current loss is 159.31.\n",
      "Current loss is 158.33.\n",
      "Current loss is 157.36.\n",
      "Current loss is 156.40.\n",
      "Current loss is 155.45.\n",
      "Current loss is 154.50.\n",
      "Current loss is 153.56.\n",
      "Current loss is 152.63.\n",
      "Current loss is 151.71.\n",
      "Current loss is 150.79.\n",
      "Current loss is 149.88.\n",
      "Current loss is 148.98.\n",
      "Current loss is 148.08.\n",
      "Current loss is 147.19.\n",
      "Current loss is 146.31.\n",
      "Current loss is 145.44.\n",
      "Current loss is 144.57.\n",
      "Current loss is 143.71.\n",
      "Current loss is 142.85.\n",
      "Current loss is 142.00.\n",
      "Current loss is 141.16.\n",
      "Current loss is 140.32.\n",
      "Current loss is 139.50.\n",
      "Current loss is 138.67.\n",
      "Current loss is 137.86.\n",
      "Current loss is 137.05.\n",
      "Current loss is 136.24.\n",
      "Current loss is 135.44.\n",
      "Current loss is 134.65.\n",
      "Current loss is 133.86.\n",
      "Current loss is 133.08.\n",
      "Current loss is 132.31.\n",
      "Current loss is 131.54.\n",
      "Current loss is 130.78.\n",
      "Current loss is 130.02.\n",
      "Current loss is 129.27.\n",
      "Current loss is 128.53.\n",
      "Current loss is 127.79.\n",
      "Current loss is 127.05.\n",
      "Current loss is 126.32.\n",
      "Current loss is 125.60.\n",
      "Current loss is 124.88.\n"
     ]
    }
   ],
   "source": [
    "using DataStructures\n",
    "using TensorFlow\n",
    "using Distributions\n",
    "using Printf\n",
    "\n",
    "# Generate some synthetic data\n",
    "x = randn(100, 50)\n",
    "w = randn(50, 10)\n",
    "y_prob = exp.(x*w)\n",
    "y_prob ./= sum(y_prob,dims=2)\n",
    "\n",
    "function draw(probs)\n",
    "    y = zeros(size(probs))\n",
    "    for i in 1:size(probs, 1)\n",
    "        idx = rand(Categorical(probs[i, :]))\n",
    "        y[i, idx] = 1\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "y = draw(y_prob)\n",
    "\n",
    "# Build the model\n",
    "sess = Session(Graph());\n",
    "\n",
    "X = placeholder(Float64, shape=[-1, 50])\n",
    "Y_obs = placeholder(Float64, shape=[-1, 10])\n",
    "\n",
    "variable_scope(\"logisitic_model\"; initializer=Normal(0, .001)) do\n",
    "    global W = get_variable(\"W\", [50, 10], Float64)\n",
    "    global B = get_variable(\"B\", [10], Float64)\n",
    "end\n",
    "\n",
    "Y=nn.softmax(X*W + B)\n",
    "\n",
    "Loss = -reduce_sum(log(Y).*Y_obs)\n",
    "optimizer = train.AdamOptimizer()\n",
    "minimize_op = train.minimize(optimizer, Loss)\n",
    "saver = train.Saver()\n",
    "\n",
    "# Run training\n",
    "run(sess, global_variables_initializer())\n",
    "checkpoint_path = mktempdir()\n",
    "@info(\"Checkpoint files saved in $checkpoint_path\")\n",
    "for epoch in 1:100\n",
    "    cur_loss, _ = run(sess, [Loss, minimize_op], Dict(X=>x, Y_obs=>y))\n",
    "    println(@sprintf(\"Current loss is %.2f.\", cur_loss))\n",
    "    train.save(saver, sess, joinpath(checkpoint_path, \"logistic\"), global_step=epoch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-20 20:36:52.771640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:36:52.772064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569\n",
      "pciBusID: 0000:02:00.0\n",
      "2019-08-20 20:36:52.772087: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-08-20 20:36:52.772095: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2019-08-20 20:36:52.772102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2019-08-20 20:36:52.772109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2019-08-20 20:36:52.772115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-08-20 20:36:52.772121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-08-20 20:36:52.772128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-08-20 20:36:52.772163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:36:52.772508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:36:52.772844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-08-20 20:36:52.772869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-20 20:36:52.772873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-08-20 20:36:52.772877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-08-20 20:36:52.772933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:36:52.773284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:36:52.773627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5637 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "┌ Info: \n",
      "│   epoch = 1\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 2\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 3\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 4\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 5\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 6\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 7\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 8\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 9\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 10\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 11\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 12\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 13\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 14\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 15\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 16\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 17\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 18\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 19\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 20\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 21\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 22\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 23\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 24\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 25\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 26\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 27\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 28\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 29\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 30\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 31\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 32\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 33\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 34\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 35\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 36\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 37\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 38\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 39\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 40\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 41\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 42\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 43\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 44\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 45\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 46\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 47\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 48\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 49\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 50\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 51\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 52\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 53\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 54\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 55\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 56\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 57\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 58\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 59\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 60\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 61\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 62\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 63\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 64\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 65\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 66\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 67\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 68\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 69\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 70\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 71\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 72\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 73\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 74\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 75\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 76\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 77\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 78\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 79\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 80\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 81\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 82\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 83\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 84\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 85\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 86\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 87\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 88\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 89\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 90\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 91\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 92\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 93\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 94\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 95\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 96\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 97\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 98\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 99\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 100\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 101\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 102\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 103\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 104\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 105\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 106\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 107\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 108\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 109\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 110\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 111\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 112\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 113\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 114\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 115\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 116\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 117\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 118\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 119\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 120\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 121\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 122\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 123\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 124\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 125\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 126\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 127\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 128\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 129\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 130\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 131\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 132\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 133\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 134\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 135\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 136\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 137\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 138\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 139\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 140\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 141\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 142\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 143\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 144\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 145\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 146\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 147\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 148\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 149\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 150\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 151\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 152\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 153\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 154\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 155\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 156\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 157\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 158\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 159\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 160\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 161\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 162\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 163\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 164\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 165\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 166\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 167\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 168\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 169\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 170\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 171\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 172\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 173\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 174\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 175\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 176\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 177\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 178\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 179\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 180\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 181\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 182\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 183\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 184\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 185\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 186\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 187\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 188\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 189\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 190\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 191\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 192\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 193\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 194\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 195\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 196\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 197\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 198\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 199\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n",
      "┌ Info: \n",
      "│   epoch = 200\n",
      "│   loss = 39.04266288265036\n",
      "└ @ TensorFlow /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/keras.jl:103\n"
     ]
    }
   ],
   "source": [
    "using TensorFlow; const tf = TensorFlow\n",
    "tf.enable_eager_execution()\n",
    "m = tf.Sequential()\n",
    "\n",
    "tf.add(m, tf.Dense(3,10))\n",
    "tf.add(m, tf.Relu())\n",
    "tf.add(m, tf.Dense(10, 3))\n",
    "\n",
    "x=constant(randn(5,3))\n",
    "y=3x+5\n",
    "tf.compile(m, optimizer=tf.SGD(lr=1e-4), loss=tf.mse)\n",
    "tf.fit(m, x, y, n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using TensorFlow\n",
    "include(\"mnist_loader.jl\")\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "sess = Session(Graph())\n",
    "\n",
    "x = placeholder(Float32)\n",
    "y_ = placeholder(Float32)\n",
    "\n",
    "W = Variable(zeros(Float32, 784, 10))\n",
    "b = Variable(zeros(Float32, 10))\n",
    "\n",
    "run(sess, global_variables_initializer())\n",
    "\n",
    "y = nn.softmax(x*W + b)\n",
    "\n",
    "cross_entropy = reduce_mean(-reduce_sum(y_ .* log(y), axis=[2]))\n",
    "train_step = train.minimize(train.GradientDescentOptimizer(.00001), cross_entropy)\n",
    "\n",
    "correct_prediction = argmax(y, 2) .== argmax(y_, 2)\n",
    "accuracy=reduce_mean(cast(correct_prediction, Float32))\n",
    "\n",
    "for i in 1:1000\n",
    "    batch = next_batch(loader, 100)\n",
    "    run(sess, train_step, Dict(x=>batch[1], y_=>batch[2]))\n",
    "end\n",
    "\n",
    "testx, testy = load_test_set()\n",
    "\n",
    "println(run(sess, accuracy, Dict(x=>testx, y_=>testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-20 20:51:09.377496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:51:09.378215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.569\n",
      "pciBusID: 0000:02:00.0\n",
      "2019-08-20 20:51:09.378258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-08-20 20:51:09.378270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2019-08-20 20:51:09.378278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2019-08-20 20:51:09.378287: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2019-08-20 20:51:09.378294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-08-20 20:51:09.378302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-08-20 20:51:09.378310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-08-20 20:51:09.378367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:51:09.379006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:51:09.379508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-08-20 20:51:09.379552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-20 20:51:09.379567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-08-20 20:51:09.379581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-08-20 20:51:09.379686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:51:09.380438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-20 20:51:09.381089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5637 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "using DataStructures\n",
    "using TensorFlow\n",
    "using Distributions\n",
    "include(\"mnist_loader.jl\");\n",
    "\n",
    "loader = DataLoader();\n",
    "\n",
    "session = Session(Graph());\n",
    "\n",
    "function weight_variable(shape)\n",
    "    initial = map(Float32, rand(Normal(0, .001), shape...))\n",
    "    return Variable(initial)\n",
    "    end;\n",
    "\n",
    "function bias_variable(shape)\n",
    "    initial = fill(Float32(.1), shape...)\n",
    "    return Variable(initial)\n",
    "    end;\n",
    "\n",
    "function conv2d(x, W)\n",
    "    nn.conv2d(x, W, [1, 1, 1, 1], \"SAME\")\n",
    "    end;\n",
    "\n",
    "function max_pool_2x2(x)\n",
    "    nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], \"SAME\")\n",
    "    end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor cross_entropy:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf begin\n",
    "\n",
    "    x = placeholder(Float32)\n",
    "    y_ = placeholder(Float32)\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    x_image = reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    h_conv1 = nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    W_fc1 = weight_variable([7*7*64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = nn.relu(h_pool2_flat * W_fc1 + b_fc1)\n",
    "\n",
    "    keep_prob = placeholder(Float32)\n",
    "    h_fc1_drop = nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    global y_conv = nn.softmax(h_fc1_drop * W_fc2 + b_fc2)\n",
    "\n",
    "    global cross_entropy = reduce_mean(-reduce_sum(y_.*log(y_conv), axis=[2]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteException",
     "evalue": "On worker 10:\nPython error: PyError ($(Expr(:escape, :(ccall(#= /home/dreuter/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'ValueError'>\nValueError('NodeDef mentions attr \\'explicit_paddings\\' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]; attr=dilations:list(int),default=[1, 1, 1, 1]>; NodeDef: {{node Conv2D}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).')\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/importer.py\", line 430, in import_graph_def\n    raise ValueError(str(e))\n\nerror at ./error.jl:33\n#3 at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:45\npy_with at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:20\nmake_py_graph at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:52\npy_gradients at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:73\n#29 at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/TensorFlow.jl:202\n#116 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:276\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:56\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:65\n#102 at ./task.jl:259",
     "output_type": "error",
     "traceback": [
      "On worker 10:\nPython error: PyError ($(Expr(:escape, :(ccall(#= /home/dreuter/.julia/packages/PyCall/ttONZ/src/pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'ValueError'>\nValueError('NodeDef mentions attr \\'explicit_paddings\\' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]; attr=dilations:list(int),default=[1, 1, 1, 1]>; NodeDef: {{node Conv2D}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).')\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/framework/importer.py\", line 430, in import_graph_def\n    raise ValueError(str(e))\n\nerror at ./error.jl:33\n#3 at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:45\npy_with at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:20\nmake_py_graph at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:52\npy_gradients at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/py.jl:73\n#29 at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/TensorFlow.jl:202\n#116 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:276\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:56\nrun_work_thunk at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/process_messages.jl:65\n#102 at ./task.jl:259",
      "",
      "Stacktrace:",
      " [1] #remotecall_wait#154(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::Function, ::Distributed.Worker) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/remotecall.jl:421",
      " [2] remotecall_wait(::Function, ::Distributed.Worker) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/remotecall.jl:412",
      " [3] #remotecall_wait#157(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::Function, ::Int64) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/remotecall.jl:433",
      " [4] remotecall_wait(::Function, ::Int64) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/Distributed/src/remotecall.jl:433",
      " [5] top-level scope at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/TensorFlow.jl:201",
      " [6] eval at ./boot.jl:328 [inlined]",
      " [7] eval at ./sysimg.jl:68 [inlined]",
      " [8] add_gradients_py(::Tensor{Float32}, ::Array{Any,1}, ::Nothing) at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/core.jl:1553",
      " [9] gradients at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/core.jl:1541 [inlined] (repeats 2 times)",
      " [10] compute_gradients(::TensorFlow.train.GradientDescentOptimizer, ::Tensor{Float32}, ::Nothing) at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/train.jl:49",
      " [11] #minimize#1(::Nothing, ::Nothing, ::Nothing, ::Function, ::TensorFlow.train.GradientDescentOptimizer, ::Tensor{Float32}) at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/train.jl:41",
      " [12] minimize(::TensorFlow.train.GradientDescentOptimizer, ::Tensor{Float32}) at /home/dreuter/.julia/packages/TensorFlow/Jif3t/src/train.jl:38",
      " [13] top-level scope at In[19]:1"
     ]
    }
   ],
   "source": [
    "train_step = train.minimize(train.GradientDescentOptimizer(.0001,\"gd\"), cross_entropy)\n",
    "\n",
    "correct_prediction = argmax(y_conv, 2) .== argmax(y_, 2)\n",
    "\n",
    "accuracy = reduce_mean(cast(correct_prediction, Float32))\n",
    "\n",
    "run(session, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:200\n",
    "    batch = next_batch(loader, 50)\n",
    "    if i%10 == 1\n",
    "        train_accuracy = run(session, accuracy, Dict(x=>batch[1], y_=>batch[2], keep_prob=>1.0))\n",
    "        @info(\"step $i, training accuracy $train_accuracy\")\n",
    "    end\n",
    "    run(session, train_step, Dict(x=>batch[1], y_=>batch[2], keep_prob=>.5))\n",
    "end\n",
    "\n",
    "testx, testy = load_test_set()\n",
    "test_accuracy = run(session, accuracy, Dict(x=>testx, y_=>testy, keep_prob=>1.0))\n",
    "@info(\"test accuracy $test_accuracy\")\n",
    "\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
